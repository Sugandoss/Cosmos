# GCP Cost Monitoring & AI/ML Pipeline System

A comprehensive cost monitoring system with AI/ML capabilities for GCP infrastructure, supporting both real BigQuery integration and mock data generation.

## ğŸ—ï¸ Architecture Overview

The system is organized into two main approaches:

### 1. **Real Data Pipeline** (Go Framework)
- **Location**: `go-framework/`
- **Purpose**: Connect to BigQuery, fetch real GCP cost data
- **Components**: Go adapters, monitors, triggers, data processors
- **Output**: Real cost data from your GCP billing

### 2. **Mock Data Pipeline** (Python Framework)  
- **Location**: `mock-data/`
- **Purpose**: Generate realistic synthetic data for testing
- **Components**: Python mock data generator, AI/ML pipeline
- **Output**: Realistic test data with anomalies

## ğŸ“ Directory Structure

```
infra-cost-monitor/
â”œâ”€â”€ go-framework/                 # Real BigQuery Integration
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â””â”€â”€ bigquery/
â”‚   â”‚       â””â”€â”€ client.go        # BigQuery connection & queries
â”‚   â”œâ”€â”€ vendors/gcp/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ cost_data.go     # Cost data structures
â”‚   â”‚   â”œâ”€â”€ monitors/
â”‚   â”‚   â”‚   â”œâ”€â”€ daily_monitor.go # Daily cost monitoring
â”‚   â”‚   â”‚   â”œâ”€â”€ mtd_monitor.go   # Month-to-date monitoring
â”‚   â”‚   â”‚   â””â”€â”€ dimensional_monitor.go
â”‚   â”‚   â”œâ”€â”€ triggers/
â”‚   â”‚   â”‚   â””â”€â”€ mtd_triggers.go # Alert triggers
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ data_processor.go # Data processing
â”‚   â”‚       â””â”€â”€ json_output.go    # JSON formatting
â”‚   â”œâ”€â”€ main.go                   # Go application entry point
â”‚   â”œâ”€â”€ demo.go                   # Demo/test file
â”‚   â”œâ”€â”€ go.mod                    # Go dependencies
â”‚   â””â”€â”€ go.sum                    # Go dependency lock
â”‚
â”œâ”€â”€ mock-data/                    # Mock Data Generation
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ mock_data_generator.py # Generate realistic test data
â”‚   â””â”€â”€ output/                   # Generated mock data files
â”‚       â”œâ”€â”€ composite_data.json   # Detailed cost breakdown
â”‚       â”œâ”€â”€ daily_total_data.json # Daily aggregated costs
â”‚       â”œâ”€â”€ mtd_data.json        # Month-to-date data
â”‚       â”œâ”€â”€ anomalies.json        # Anomaly records
â”‚       â””â”€â”€ summary.json          # System summary
â”‚
â”œâ”€â”€ ai_ml/                        # AI/ML Pipeline (Works with both)
â”‚   â”œâ”€â”€ cost_ai_pipeline.py      # Main AI/ML processing
â”‚   â”œâ”€â”€ cost_forecasting.py      # Cost forecasting (Prophet)
â”‚   â”œâ”€â”€ forecasts/               # Generated forecasts
â”‚   â”œâ”€â”€ chroma_db/              # Vector database
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ alert_system/                 # Alert Management
â”‚   â”œâ”€â”€ alert_manager.py         # Alert processing & notifications
â”‚   â””â”€â”€ alert_system.log         # Alert system logs
â”‚
â”œâ”€â”€ dashboard/                    # Web Dashboard
â”‚   â”œâ”€â”€ app.py                   # Flask dashboard application
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ dashboard.html       # Dashboard UI
â”‚   â””â”€â”€ dashboard.log            # Dashboard logs
â”‚
â”œâ”€â”€ slack_bot/                    # Slack Integration
â”‚   â”œâ”€â”€ slack_bot.py             # Slack bot implementation
â”‚   â”œâ”€â”€ rag_integration.py       # RAG for natural language queries
â”‚   â”œâ”€â”€ requirements.txt          # Bot dependencies
â”‚   â””â”€â”€ env_example.txt          # Environment variables template
â”‚
â”œâ”€â”€ config/                       # Configuration Files
â”‚   â””â”€â”€ alert_thresholds.json    # Alert configuration
â”‚
â”œâ”€â”€ data/                         # System Data
â”‚   â”œâ”€â”€ alert_history.json       # Alert history
â”‚   â””â”€â”€ logs/                    # System logs
â”‚
â”œâ”€â”€ tests/                        # Test Files
â”‚   â”œâ”€â”€ test_alerts_direct.py    # Direct alert testing
â”‚   â”œâ”€â”€ test_anomaly_alert.py    # Anomaly alert testing
â”‚   â””â”€â”€ force_alert_test.py      # Force alert testing
â”‚
â””â”€â”€ scripts/                      # System Scripts
    â”œâ”€â”€ run_complete_system.sh   # Run entire system
    â”œâ”€â”€ run_go_framework.sh      # Run Go framework only
    â”œâ”€â”€ run_mock_data.sh         # Run mock data only
    â””â”€â”€ run_simple_system.sh     # Run simplified system
```

## ğŸš€ Quick Start

### Option 1: Mock Data (Recommended for Testing)
```bash
# Run with mock data (realistic GCP costs)
./scripts/run_mock_data.sh
```

### Option 2: Real BigQuery Data (Production)
```bash
# Run with real GCP data
./scripts/run_go_framework.sh
```

### Option 3: Complete System
```bash
# Run everything (mock data + all components)
./scripts/run_complete_system.sh
```

## ğŸ”§ Configuration

### Alert Thresholds
Edit `config/alert_thresholds.json`:
```json
{
  "cost_spike_threshold": 1.0,
  "cost_spike_percentage": 10.0,
  "anomaly_threshold": 2.0
}
```

### Environment Variables
Copy `slack_bot/env_example.txt` to `slack_bot/.env` and configure:
- `SLACK_BOT_TOKEN`
- `SLACK_SIGNING_SECRET`
- `SLACK_APP_TOKEN`

## ğŸ“Š System Components

### 1. **Data Sources**
- **Real Data**: Go framework connects to BigQuery
- **Mock Data**: Python generator creates realistic test data

### 2. **AI/ML Pipeline**
- **Anomaly Detection**: Identifies cost spikes and unusual patterns
- **Cost Forecasting**: Predicts future costs using Prophet
- **Semantic Search**: Natural language queries via RAG

### 3. **Alert System**
- **Slack Notifications**: Real-time cost alerts
- **Email Notifications**: Backup alert system
- **Web Dashboard**: Real-time monitoring interface

### 4. **Slack Bot**
- **Natural Language Queries**: Ask about costs in plain English
- **Cost Statistics**: Get detailed cost breakdowns
- **Alert Management**: Configure and manage alerts

## ğŸ¯ Use Cases

### Development/Testing
- Use mock data for rapid development
- Test alert configurations
- Validate AI/ML pipeline

### Production
- Connect to real BigQuery billing data
- Monitor actual GCP costs
- Get real-time alerts for cost spikes

## ğŸ“ˆ Features

- **Real-time Cost Monitoring**: Track daily, MTD, and dimensional costs
- **Anomaly Detection**: AI-powered cost spike detection
- **Cost Forecasting**: Predict future costs with 30-day forecasts
- **Natural Language Queries**: Ask about costs in plain English
- **Slack Integration**: Real-time alerts and queries
- **Web Dashboard**: Real-time monitoring with charts and alerts
- **Alert Management**: Configurable thresholds and notifications

## ğŸ” Monitoring

- **Dashboard**: http://localhost:5001
- **Logs**: Check `data/logs/` directory
- **Alerts**: View `data/alert_history.json`
- **Forecasts**: Check `ai_ml/forecasts/` directory

## ğŸ› ï¸ Troubleshooting

### Common Issues
1. **Port 5000 in use**: Dashboard uses port 5001
2. **SQLite version conflicts**: Chroma DB uses pysqlite3 patch
3. **Slack bot not responding**: Check environment variables and app permissions

### Logs
- Alert System: `data/logs/alert_system.log`
- Dashboard: `data/logs/dashboard.log`
- AI/ML Pipeline: Check console output

## ğŸ“ Development

### Adding New Services
1. Update mock data generator (`mock-data/scripts/mock_data_generator.py`)
2. Add service to Go monitors (`go-framework/vendors/gcp/monitors/`)
3. Update forecasting (`ai_ml/cost_forecasting.py`)

### Custom Alerts
1. Modify alert thresholds in `config/alert_thresholds.json`
2. Add new alert types in `alert_system/alert_manager.py`
3. Test with `tests/force_alert_test.py`
